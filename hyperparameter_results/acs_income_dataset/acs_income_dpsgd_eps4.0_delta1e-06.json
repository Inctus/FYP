{
    "mlp_hidden_dim_l0": 64,
    "mlp_hidden_dim_l1": 128,
    "mlp_dropout_p": 0.2,
    "num_epochs": 55,
    "learning_rate": 0.026593814446910904,
    "batch_size": 1024,
    "patience": 20,
    "max_grad_norm": 4.090079197846532
}