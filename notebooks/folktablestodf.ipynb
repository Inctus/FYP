{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb365a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLKTABLES_DATA_PATH = \"/vol/bitbucket/hh2721/folktables\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7519103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, ACSIncome, generate_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf952d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year=\"2018\",\n",
    "                            horizon=\"1-Year\",\n",
    "                            survey=\"person\",\n",
    "                            root_dir=FOLKTABLES_DATA_PATH)\n",
    "\n",
    "ca_data = data_source.get_data(states=[\"CA\"], download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ba5d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>COW</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>POBP</th>\n",
       "      <th>RELP</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>RAC1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9610.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9610.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGEP  COW  SCHL  MAR    OCCP  POBP  RELP  WKHP  SEX  RAC1P\n",
       "0  30.0  6.0  14.0  1.0  9610.0   6.0  16.0  40.0  1.0    8.0\n",
       "1  21.0  4.0  16.0  5.0  1970.0   6.0  17.0  20.0  1.0    1.0\n",
       "2  65.0  2.0  22.0  5.0  2040.0   6.0  17.0   8.0  1.0    1.0\n",
       "3  33.0  1.0  14.0  3.0  9610.0  36.0  16.0  40.0  1.0    1.0\n",
       "4  18.0  2.0  19.0  5.0  1021.0   6.0  17.0  18.0  2.0    1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_features, ca_labels, _ = ACSIncome.df_to_pandas(ca_data)\n",
    "\n",
    "ca_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ddf6069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PINCP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PINCP\n",
       "0  False\n",
       "1  False\n",
       "2  False\n",
       "3  False\n",
       "4  False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_labels.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd98e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "A collection of constants used throughout the project.\n",
    "\"\"\"\n",
    "\n",
    "# For reproducibility, we set a random seed.\n",
    "RANDOM_SEED = 69420\n",
    "\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.15\n",
    "TEST_SPLIT = 0.15\n",
    "# The splits should sum to 1.0\n",
    "assert TRAIN_SPLIT + VAL_SPLIT + TEST_SPLIT == 1.0, \\\n",
    "    \"Train, validation, and test splits must sum to 1.0\"\n",
    "\n",
    "\n",
    "\n",
    "class FairnessDataset(TorchDataset):\n",
    "    \"\"\"\n",
    "    Wraps pre-processed features, labels, and optional protected attributes as a PyTorch Dataset.\n",
    "    Data is expected to be in NumPy array format and will be converted to PyTorch tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features_np: np.ndarray, labels_np: np.ndarray, protected_attrs_np: np.ndarray | None = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features_np: NumPy array of features.\n",
    "            labels_np: NumPy array of labels.\n",
    "            protected_attrs_np: Optional NumPy array of protected attributes.\n",
    "        \"\"\"\n",
    "        self.features = torch.tensor(features_np, dtype=torch.float32)\n",
    "        # Ensure labels are float32 for losses like BCELoss\n",
    "        self.labels = torch.tensor(labels_np, dtype=torch.float32) \n",
    "        \n",
    "        if protected_attrs_np is not None:\n",
    "            self.protected_attrs = torch.tensor(protected_attrs_np, dtype=torch.float32)\n",
    "        else:\n",
    "            self.protected_attrs = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return features, labels, and optionally protected attributes.\n",
    "        \"\"\"\n",
    "        item_features = self.features[idx]\n",
    "        item_labels = self.labels[idx]\n",
    "        \n",
    "        if self.protected_attrs is not None:\n",
    "            return item_features, item_labels, self.protected_attrs[idx]\n",
    "        else:\n",
    "            return item_features, item_labels\n",
    "\n",
    "\n",
    "class BaseDataset(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for dataset wrappers that provides a universal interface\n",
    "    for loading, processing and accessing datasets in any format.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the dataset by loading the underlying AIF360 data.\"\"\"\n",
    "        self._aif360_dataset_original = self.load_data()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads the dataset from the AIF360 dataset object.\n",
    "        Must be implemented by subclasses.\n",
    "        \n",
    "        Returns:\n",
    "            AIF360 dataset object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"load_data() must be implemented in subclasses\")\n",
    "    \n",
    "    def to_torch(self, include_protected=True) -> Tuple[FairnessDataset, FairnessDataset, FairnessDataset]:\n",
    "        \"\"\"\n",
    "        Processes the AIF360 dataset:\n",
    "        1. Extracts features, labels, and (optionally) protected attributes.\n",
    "        2. Splits data into train, validation, and test sets.\n",
    "        3. Normalizes non-binary features (scaler fitted on training data only).\n",
    "        4. Wraps the processed data into FairnessDataset instances.\n",
    "\n",
    "        Args:\n",
    "            include_protected: If True, protected attributes will be extracted and included.\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (train_dataset, val_dataset, test_dataset) as FairnessDataset instances.\n",
    "        \"\"\"\n",
    "        aif360_data = self._aif360_dataset_original\n",
    "\n",
    "        # 1. Extract and validate data\n",
    "        X_all_np = aif360_data.features.astype(np.float32)\n",
    "        # This should work because AIF360 datasets are already\n",
    "        # One-Hot encoded for categorical features. i.e. no strings here! Let's verify.\n",
    "\n",
    "        y_all_np = aif360_data.labels.ravel().astype(np.float32)\n",
    "        \n",
    "        if X_all_np.shape[0] == 0:\n",
    "            raise ValueError(\"Dataset contains no samples\")\n",
    "        if X_all_np.shape[1] == 0:\n",
    "            raise ValueError(\"Dataset contains no features\")\n",
    "        \n",
    "        prot_all_np = None\n",
    "        if include_protected:\n",
    "            if (hasattr(aif360_data, 'protected_attributes') and \n",
    "                aif360_data.protected_attributes is not None and\n",
    "                aif360_data.protected_attributes.shape[1] > 0):\n",
    "                prot_all_np = aif360_data.protected_attributes.astype(np.float32)\n",
    "            else:\n",
    "                print(\"Warning: include_protected is True, but protected_attributes are not available or empty.\")\n",
    "\n",
    "        # 2. Create deterministic split indices - SIMPLIFIED APPROACH\n",
    "        total_size = X_all_np.shape[0]\n",
    "        train_size = int(TRAIN_SPLIT * total_size)\n",
    "        val_size = int(VAL_SPLIT * total_size)\n",
    "        test_size = total_size - train_size - val_size\n",
    "        \n",
    "        if train_size == 0:\n",
    "            raise ValueError(\"Training set would be empty with current split ratios\")\n",
    "        \n",
    "        # Generate shuffled indices deterministically\n",
    "        rng = np.random.RandomState(RANDOM_SEED)\n",
    "        shuffled_indices = rng.permutation(total_size)\n",
    "        \n",
    "        train_indices = shuffled_indices[:train_size]\n",
    "        val_indices = shuffled_indices[train_size:train_size + val_size]\n",
    "        test_indices = shuffled_indices[train_size + val_size:]\n",
    "\n",
    "        # 3. Split data\n",
    "        X_train_np = X_all_np[train_indices]\n",
    "        X_val_np = X_all_np[val_indices] if val_size > 0 else np.array([]).reshape(0, X_all_np.shape[1])\n",
    "        X_test_np = X_all_np[test_indices] if test_size > 0 else np.array([]).reshape(0, X_all_np.shape[1])\n",
    "        \n",
    "        y_train_np = y_all_np[train_indices]\n",
    "        y_val_np = y_all_np[val_indices] if val_size > 0 else np.array([])\n",
    "        y_test_np = y_all_np[test_indices] if test_size > 0 else np.array([])\n",
    "        \n",
    "        prot_train_np = prot_val_np = prot_test_np = None\n",
    "        if prot_all_np is not None:\n",
    "            prot_train_np = prot_all_np[train_indices]\n",
    "            prot_val_np = prot_all_np[val_indices] if val_size > 0 else np.array([]).reshape(0, prot_all_np.shape[1])\n",
    "            prot_test_np = prot_all_np[test_indices] if test_size > 0 else np.array([]).reshape(0, prot_all_np.shape[1])\n",
    "\n",
    "        # 4. Scale features (sklearn handles binary features gracefully)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_np = scaler.fit_transform(X_train_np)\n",
    "        if val_size > 0:\n",
    "            X_val_np = scaler.transform(X_val_np)\n",
    "        if test_size > 0:\n",
    "            X_test_np = scaler.transform(X_test_np)\n",
    "\n",
    "        # 5. Create FairnessDataset instances\n",
    "        train_dataset = FairnessDataset(X_train_np, y_train_np, prot_train_np if include_protected else None)\n",
    "        val_dataset = FairnessDataset(X_val_np, y_val_np, prot_val_np if include_protected else None)\n",
    "        test_dataset = FairnessDataset(X_test_np, y_test_np, prot_test_np if include_protected else None)\n",
    "        \n",
    "        print(f\"Dataset sizes - Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc19e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from folktables import ACSDataSource, ACSIncome\n",
    "\n",
    "from aif360.datasets import StandardDataset\n",
    "\n",
    "# Fixed data path as per your notebook\n",
    "FOLKTABLES_DATA_PATH = \"/vol/bitbucket/hh2721/folktables\"\n",
    "\n",
    "class ACSIncomeDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Simplified ACS Income Dataset class for loading and preprocessing data from Folktables.\n",
    "\n",
    "    This class is configured for:\n",
    "    - Survey Year: 2018\n",
    "    - Horizon: 1-Year\n",
    "    - Survey: Person\n",
    "    - Sensitive Attribute: Sex (Male privileged)\n",
    "    - Data Path: /vol/bitbucket/hh2721/folktables\n",
    "    - Download Data: False (assumes data is pre-downloaded)\n",
    "\n",
    "    It handles loading ACS Income data and applying standard preprocessing steps\n",
    "    like one-hot encoding via AIF360's StandardDataset.\n",
    "\n",
    "    Folktables features for ACSIncome:\n",
    "    ['AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'WKHP', 'SEX', 'RAC1P']\n",
    "    Target: PINCP (Income) > $50,000 (binary)\n",
    "    Protected Attribute: SEX (1 for Male, 2 for Female. Privileged is Male (1.0)).\n",
    "    \"\"\"\n",
    "\n",
    "    _STATES = [\"CA\"]\n",
    "    _SURVEY_YEAR = '2018'\n",
    "    _HORIZON = '1-Year'\n",
    "    _SURVEY = 'person'\n",
    "    _SENSITIVE_ATTRIBUTE_NAME = 'SEX' # Folktables column name\n",
    "    _DOWNLOAD_DATA = False\n",
    "\n",
    "    def __init__(self):\n",
    "        if not os.path.exists(FOLKTABLES_DATA_PATH):\n",
    "            # If data is not downloaded and download is False, this will likely fail later.\n",
    "            # Consider adding a more robust check or instruction.\n",
    "            print(f\"Warning: Folktables data path {FOLKTABLES_DATA_PATH} does not exist. \"\n",
    "                  \"Data loading might fail as download_data is False.\")\n",
    "        \n",
    "        self.features_dim = None # Will be populated after load_data\n",
    "\n",
    "        super().__init__() # Calls BaseDataset.__init__ -> self.load_data()\n",
    "        \n",
    "        if self._aif360_dataset_original:\n",
    "            self.features_dim = self._aif360_dataset_original.features.shape[1]\n",
    "\n",
    "    def load_data(self) -> StandardDataset:\n",
    "        \"\"\"\n",
    "        Loads and preprocesses ACS Income data using Folktables and AIF360 StandardDataset\n",
    "        with fixed configuration (2018, 1-Year, 'sex' as SA).\n",
    "        \"\"\"\n",
    "        data_source = ACSDataSource(survey_year=self._SURVEY_YEAR,\n",
    "                                    horizon=self._HORIZON,\n",
    "                                    survey=self._SURVEY,\n",
    "                                    root_dir=FOLKTABLES_DATA_PATH)\n",
    "        \n",
    "        try:\n",
    "            acs_data = data_source.get_data(states=self._STATES, download=self._DOWNLOAD_DATA)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Folktables data: {e}\")\n",
    "            print(f\"Please ensure data for states {self._STATES}, year {self._SURVEY_YEAR}, horizon {self._HORIZON} \"\n",
    "                  f\"is available at {FOLKTABLES_DATA_PATH} (download is set to False).\")\n",
    "            raise\n",
    "\n",
    "        features_df, labels_series, _ = ACSIncome.df_to_pandas(acs_data)\n",
    "        \n",
    "        df = features_df.copy()\n",
    "        # We need to map from Folktables to AIF360's expected format:\n",
    "        # Folktables uses 1 for Male and 2 for Female but AIF360 expects\n",
    "        # 1.0 for privileged and 0.0 for unprivileged. Since this is a numeric column it isn't mapped\n",
    "        # automatically by AIF360, we need to do it manually.\n",
    "        df[self._SENSITIVE_ATTRIBUTE_NAME] = df[self._SENSITIVE_ATTRIBUTE_NAME].map({1: 1.0, 2: 0.0})\n",
    "\n",
    "        label_name = 'PINCP_GT_50K'\n",
    "        df[label_name] = labels_series.astype(float)\n",
    "        favorable_classes = [1.0]\n",
    "\n",
    "        # Protected attribute is 'SEX' (1.0=Male, 0.0=Female) since we mapped it above.\n",
    "        # Male (1.0) is privileged.\n",
    "        protected_attribute_names = [self._SENSITIVE_ATTRIBUTE_NAME]\n",
    "        privileged_classes = [[1.0]] \n",
    "\n",
    "        # ACSIncome.features: ['AGEP', 'COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'WKHP', 'SEX', 'RAC1P']\n",
    "        # 'SEX' is the protected attribute. 'RAC1P' will be a regular categorical feature.\n",
    "        categorical_features_for_encoding = ['COW', 'SCHL', 'MAR', 'OCCP', 'POBP', 'RELP', 'RAC1P']\n",
    "        \n",
    "        # Ensure all columns exist\n",
    "        all_expected_cols = categorical_features_for_encoding + protected_attribute_names + ['AGEP', 'WKHP']\n",
    "        for col in all_expected_cols:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"Expected column '{col}' not found in ACSIncome features for the given configuration.\")\n",
    "\n",
    "        default_metadata = self._get_default_metadata()\n",
    "\n",
    "        dataset = StandardDataset(\n",
    "            df=df,\n",
    "            label_name=label_name,\n",
    "            favorable_classes=favorable_classes,\n",
    "            protected_attribute_names=protected_attribute_names,\n",
    "            privileged_classes=privileged_classes,\n",
    "            instance_weights_name=None,\n",
    "            categorical_features=categorical_features_for_encoding,\n",
    "            features_to_keep=[], \n",
    "            features_to_drop=[],\n",
    "            na_values=[], \n",
    "            custom_preprocessing=None, \n",
    "            metadata=default_metadata\n",
    "        )\n",
    "        \n",
    "        return dataset\n",
    "\n",
    "    def _get_default_metadata(self):\n",
    "        \"\"\"Provides default metadata for labels and the 'sex' protected attribute.\"\"\"\n",
    "        label_map = [{1.0: 'Income > $50K', 0.0: 'Income <= $50K'}]\n",
    "        # For 'SEX': Male (1.0) is privileged. Female (2.0) is unprivileged.\n",
    "        # AIF360's StandardDataset handles numeric protected attributes by keeping original values\n",
    "        # but using privileged_classes to define groups. The metadata map reflects the\n",
    "        # conceptual 0/1 mapping for fairness metrics.\n",
    "        protected_attribute_map = [{1.0: 'Male', 0.0: 'Female'}] \n",
    "\n",
    "        return {\n",
    "            'label_maps': label_map,\n",
    "            'protected_attribute_maps': protected_attribute_map\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d622a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ACSIncomeDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f466c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 136965, Val: 29349, Test: 29351\n",
      "Feature shape: torch.Size([815]), Label: 1.0, Protected: 0.0\n"
     ]
    }
   ],
   "source": [
    "train, val, test = dataset.to_torch(include_protected=True)\n",
    "\n",
    "for feat, lab, prot in train:\n",
    "    print(f\"Feature shape: {feat.shape}, Label: {lab.item()}, Protected: {prot.item()}\")\n",
    "    break  # Just print the first item for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f8c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
