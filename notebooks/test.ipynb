{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9da4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcfe7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIF360TorchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps an AIF360 BinaryLabelDataset (or similar) as a PyTorch Dataset.\n",
    "    Exposes:\n",
    "      - features:          torch.float32 tensor of shape (n_samples, n_features)\n",
    "      - labels:            torch.long tensor of shape (n_samples,)\n",
    "      - protected_attrs:   torch.float32 tensor of shape (n_samples, n_protected_attrs)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, aif360_dataset, include_protected=True, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            aif360_dataset:      an AIF360 dataset object (e.g. AdultDataset(), COMPASDataset(), etc.)\n",
    "            include_protected:   if True, will also expose protected_attributes\n",
    "            transform:           optional callable to apply to each feature vector\n",
    "        \"\"\"\n",
    "        # raw numpy arrays from AIF360\n",
    "        X = aif360_dataset.features\n",
    "        y = aif360_dataset.labels.ravel()\n",
    "        \n",
    "        # protected_attributes is shape (n_samples, n_protected_attrs)\n",
    "        if include_protected:\n",
    "            prot = aif360_dataset.protected_attributes\n",
    "            self.protected_attrs = torch.tensor(prot, dtype=torch.float32)\n",
    "        else:\n",
    "            self.protected_attrs = None\n",
    "        \n",
    "        # convert to torch tensors\n",
    "        self.features = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels   = torch.tensor(y, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        sample = {\n",
    "            'features': x,\n",
    "            'label':     self.labels[idx]\n",
    "        }\n",
    "        if self.protected_attrs is not None:\n",
    "            sample['protected_attributes'] = self.protected_attrs[idx]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36047ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AdultDataset in module aif360.datasets.adult_dataset:\n",
      "\n",
      "class AdultDataset(aif360.datasets.standard_dataset.StandardDataset)\n",
      " |  AdultDataset(label_name='income-per-year', favorable_classes=['>50K', '>50K.'], protected_attribute_names=['race', 'sex'], privileged_classes=[['White'], ['Male']], instance_weights_name=None, categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country'], features_to_keep=[], features_to_drop=['fnlwgt'], na_values=['?'], custom_preprocessing=None, metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}], 'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-white'}, {1.0: 'Male', 0.0: 'Female'}]})\n",
      " |  \n",
      " |  Adult Census Income Dataset.\n",
      " |  \n",
      " |  See :file:`aif360/data/raw/adult/README.md`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AdultDataset\n",
      " |      aif360.datasets.standard_dataset.StandardDataset\n",
      " |      aif360.datasets.binary_label_dataset.BinaryLabelDataset\n",
      " |      aif360.datasets.structured_dataset.StructuredDataset\n",
      " |      aif360.datasets.dataset.Dataset\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, label_name='income-per-year', favorable_classes=['>50K', '>50K.'], protected_attribute_names=['race', 'sex'], privileged_classes=[['White'], ['Male']], instance_weights_name=None, categorical_features=['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'native-country'], features_to_keep=[], features_to_drop=['fnlwgt'], na_values=['?'], custom_preprocessing=None, metadata={'label_maps': [{1.0: '>50K', 0.0: '<=50K'}], 'protected_attribute_maps': [{1.0: 'White', 0.0: 'Non-white'}, {1.0: 'Male', 0.0: 'Female'}]})\n",
      " |      See :obj:`StandardDataset` for a description of the arguments.\n",
      " |      \n",
      " |      Examples:\n",
      " |          The following will instantiate a dataset which uses the `fnlwgt`\n",
      " |          feature:\n",
      " |      \n",
      " |          >>> from aif360.datasets import AdultDataset\n",
      " |          >>> ad = AdultDataset(instance_weights_name='fnlwgt',\n",
      " |          ... features_to_drop=[])\n",
      " |          WARNING:root:Missing Data: 3620 rows removed from dataset.\n",
      " |          >>> not np.all(ad.instance_weights == 1.)\n",
      " |          True\n",
      " |      \n",
      " |          To instantiate a dataset which utilizes only numerical features and\n",
      " |          a single protected attribute, run:\n",
      " |      \n",
      " |          >>> single_protected = ['sex']\n",
      " |          >>> single_privileged = [['Male']]\n",
      " |          >>> ad = AdultDataset(protected_attribute_names=single_protected,\n",
      " |          ... privileged_classes=single_privileged,\n",
      " |          ... categorical_features=[],\n",
      " |          ... features_to_keep=['age', 'education-num'])\n",
      " |          >>> print(ad.feature_names)\n",
      " |          ['education-num', 'age', 'sex']\n",
      " |          >>> print(ad.label_names)\n",
      " |          ['income-per-year']\n",
      " |      \n",
      " |          Note: the `protected_attribute_names` and `label_name` are kept even\n",
      " |          if they are not explicitly given in `features_to_keep`.\n",
      " |      \n",
      " |          In some cases, it may be useful to keep track of a mapping from\n",
      " |          `float -> str` for protected attributes and/or labels. If our use\n",
      " |          case differs from the default, we can modify the mapping stored in\n",
      " |          `metadata`:\n",
      " |      \n",
      " |          >>> label_map = {1.0: '>50K', 0.0: '<=50K'}\n",
      " |          >>> protected_attribute_maps = [{1.0: 'Male', 0.0: 'Female'}]\n",
      " |          >>> ad = AdultDataset(protected_attribute_names=['sex'],\n",
      " |          ... categorical_features=['workclass', 'education', 'marital-status',\n",
      " |          ... 'occupation', 'relationship', 'native-country', 'race'],\n",
      " |          ... privileged_classes=[['Male']], metadata={'label_map': label_map,\n",
      " |          ... 'protected_attribute_maps': protected_attribute_maps})\n",
      " |      \n",
      " |          Note that we are now adding `race` as a `categorical_features`.\n",
      " |          Now this information will stay attached to the dataset and can be\n",
      " |          used for more descriptive visualizations.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from aif360.datasets.binary_label_dataset.BinaryLabelDataset:\n",
      " |  \n",
      " |  validate_dataset(self)\n",
      " |      Error checking and type validation.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: `labels` must be shape [n, 1].\n",
      " |          ValueError: `favorable_label` and `unfavorable_label` must be the\n",
      " |              only values present in `labels`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from aif360.datasets.structured_dataset.StructuredDataset:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Equality comparison for StructuredDatasets.\n",
      " |      \n",
      " |      Note: Compares all fields other than those specified in `ignore_fields`.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  align_datasets(self, other)\n",
      " |      Align the other dataset features, labels and protected_attributes to\n",
      " |      this dataset.\n",
      " |      \n",
      " |      Args:\n",
      " |          other (StructuredDataset): Other dataset that needs to be aligned\n",
      " |      \n",
      " |      Returns:\n",
      " |          StructuredDataset: New aligned dataset\n",
      " |  \n",
      " |  convert_to_dataframe(self, de_dummy_code=False, sep='=', set_category=True)\n",
      " |      Convert the StructuredDataset to a :obj:`pandas.DataFrame`.\n",
      " |      \n",
      " |      Args:\n",
      " |          de_dummy_code (bool): Performs de_dummy_coding, converting dummy-\n",
      " |              coded columns to categories. If `de_dummy_code` is `True` and\n",
      " |              this dataset contains mappings for label and/or protected\n",
      " |              attribute values to strings in the `metadata`, this method will\n",
      " |              convert those as well.\n",
      " |          sep (char): Separator between the prefix in the dummy indicators and\n",
      " |              the dummy-coded categorical levels.\n",
      " |          set_category (bool): Set the de-dummy coded features to categorical\n",
      " |              type.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (pandas.DataFrame, dict):\n",
      " |      \n",
      " |              * `pandas.DataFrame`: Equivalent dataframe for a dataset. All\n",
      " |                columns will have only numeric values. The\n",
      " |                `protected_attributes` field in the dataset will override the\n",
      " |                values in the `features` field.\n",
      " |      \n",
      " |              * `dict`: Attributes. Will contain additional information pulled\n",
      " |                from the dataset such as `feature_names`, `label_names`,\n",
      " |                `protected_attribute_names`, `instance_names`,\n",
      " |                `instance_weights`, `privileged_protected_attributes`,\n",
      " |                `unprivileged_protected_attributes`. The metadata will not be\n",
      " |                returned.\n",
      " |  \n",
      " |  export_dataset(self, export_metadata=False)\n",
      " |      Export the dataset and supporting attributes\n",
      " |      TODO: The preferred file format is HDF\n",
      " |  \n",
      " |  import_dataset(self, import_metadata=False)\n",
      " |      Import the dataset and supporting attributes\n",
      " |      TODO: The preferred file format is HDF\n",
      " |  \n",
      " |  split(self, num_or_size_splits, shuffle=False, seed=None)\n",
      " |      Split this dataset into multiple partitions.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_or_size_splits (array or int): If `num_or_size_splits` is an\n",
      " |              int, *k*, the value is the number of equal-sized folds to make\n",
      " |              (if *k* does not evenly divide the dataset these folds are\n",
      " |              approximately equal-sized). If `num_or_size_splits` is an array\n",
      " |              of type int, the values are taken as the indices at which to\n",
      " |              split the dataset. If the values are floats (< 1.), they are\n",
      " |              considered to be fractional proportions of the dataset at which\n",
      " |              to split.\n",
      " |          shuffle (bool, optional): Randomly shuffle the dataset before\n",
      " |              splitting.\n",
      " |          seed (int or array_like): Takes the same argument as\n",
      " |              :func:`numpy.random.seed()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          list: Splits. Contains *k* or `len(num_or_size_splits) + 1`\n",
      " |          datasets depending on `num_or_size_splits`.\n",
      " |  \n",
      " |  subset(self, indexes)\n",
      " |      Subset of dataset based on position\n",
      " |      Args:\n",
      " |          indexes: iterable which contains row indexes\n",
      " |      \n",
      " |      Returns:\n",
      " |          `StructuredDataset`: subset of dataset based on indexes\n",
      " |  \n",
      " |  temporarily_ignore(self, *fields)\n",
      " |      Temporarily add the fields provided to `ignore_fields`.\n",
      " |      \n",
      " |      To be used in a `with` statement. Upon completing the `with` block,\n",
      " |      `ignore_fields` is restored to its original value.\n",
      " |      \n",
      " |      Args:\n",
      " |          *fields: Additional fields to ignore for equality comparison within\n",
      " |              the scope of this context manager, e.g.\n",
      " |              `temporarily_ignore('features', 'labels')`. The temporary\n",
      " |              `ignore_fields` attribute is the union of the old attribute and\n",
      " |              the set of these fields.\n",
      " |      \n",
      " |      Examples:\n",
      " |          >>> sd = StructuredDataset(...)\n",
      " |          >>> modified = sd.copy()\n",
      " |          >>> modified.labels = sd.labels + 1\n",
      " |          >>> assert sd != modified\n",
      " |          >>> with sd.temporarily_ignore('labels'):\n",
      " |          >>>     assert sd == modified\n",
      " |          >>> assert 'labels' not in sd.ignore_fields\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from aif360.datasets.structured_dataset.StructuredDataset:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from aif360.datasets.dataset.Dataset:\n",
      " |  \n",
      " |  copy(self, deepcopy=False)\n",
      " |      Convenience method to return a copy of this dataset.\n",
      " |      \n",
      " |      Args:\n",
      " |          deepcopy (bool, optional): :func:`~copy.deepcopy` this dataset if\n",
      " |              `True`, shallow copy otherwise.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Dataset: A new dataset with fields copied from this object and\n",
      " |          metadata set accordingly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from aif360.datasets.dataset.Dataset:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import AdultDataset\n",
    "\n",
    "help(AdultDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84059612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load an AIF360 dataset\n",
    "from aif360.datasets import AdultDataset\n",
    "aif_data = AdultDataset(protected_attribute_names=['sex'], privileged_classes=[['Male']], categorical_features=[], features_to_keep=['age', 'education-num'])\n",
    "\n",
    "# 2. wrap it\n",
    "torch_ds = AIF360TorchDataset(aif_data, include_protected=True)\n",
    "\n",
    "# 3. build a DataLoader\n",
    "loader = DataLoader(torch_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457acba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: torch.Size([64, 3])\n",
      "label: torch.Size([64])\n",
      "protected_attrs: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "\n",
    "features, label, protected_attrs = batch['features'], batch['label'], batch['protected_attributes']\n",
    "print(f\"features: {features.shape}\")\n",
    "print(f\"label: {label.shape}\")\n",
    "print(f\"protected_attrs: {protected_attrs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990896da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
